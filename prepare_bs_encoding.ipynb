{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from sys import maxsize\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')\n",
    "dir_home = os.getcwd()\n",
    "dir_ref = dir_home +\"/ref\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def async_move(event):\n",
    "  return 1\n",
    "\n",
    "def sync_move(event1, event2):\n",
    "  if event1[\"label\"] != event2[\"label\"]:\n",
    "    return maxsize # infinity in definition\n",
    "  else:\n",
    "    data1 = event1[\"data\"]\n",
    "    data2 = event2[\"data\"]\n",
    "    keys = set(list(data1.keys()) + list(data2.keys()))\n",
    "    penalty = 0\n",
    "    for k in keys:\n",
    "      if (k in data1 and not k in data2) or (k in data2 and not k in data1):\n",
    "        penalty += 1\n",
    "      else:\n",
    "        penalty += (0 if data1[k] == data2[k] else 1)\n",
    "    return penalty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sync_move_standard(event1, event2):\n",
    "  if event1[\"label\"] != event2[\"label\"]:\n",
    "    return maxsize # infinity in definition\n",
    "  else:\n",
    "    data1 = event1[\"data\"]\n",
    "    data2 = event2[\"data\"]\n",
    "    keys = set(list(data1.keys()) + list(data2.keys()))\n",
    "    penalty = 0\n",
    "    for k in keys:\n",
    "      if (k in data1 and not k in data2) or (k in data2 and not k in data1):\n",
    "        penalty += 1\n",
    "      else:\n",
    "        penalty += (0 if data1[k] == data2[k] else 1)\n",
    "    return penalty\n",
    "\n",
    "def sync_move_levenshtein(event1, event2):\n",
    "  return maxsize if event1[\"label\"] != event2[\"label\"] else 0\n",
    "\n",
    "def distance_faster(trace1, trace2, sync_move):\n",
    "  delta = [ [0 for j in range(0,len(trace2)+1)] for i in range(0,len(trace1)+1)]\n",
    "\n",
    "  for i in range(0,len(trace1)+1):\n",
    "    for j in range(0,len(trace2)+1):\n",
    "      if i == 0 and j == 0:\n",
    "        continue # delta[i][j] = 0\n",
    "      elif i == 0:\n",
    "        delta[i][j] = async_move(trace2[j-1])\n",
    "      elif j == 0:\n",
    "        delta[i][j] = async_move(trace1[j-1])\n",
    "      else:\n",
    "        delta[i][j] = min(\n",
    "                delta[i-1][j-1] + sync_move(trace1[i-1], trace2[j-1]),\n",
    "                delta[i-1][j] + async_move(trace1[i-1]),\n",
    "                delta[i][j-1] + async_move(trace2[j-1]))\n",
    "  return delta[len(trace1)][len(trace2)]\n",
    "\n",
    "def distance_standard(trace1, trace2):\n",
    "  return distance_faster(trace1, trace2, sync_move_standard)\n",
    "\n",
    "def distance_levenshtein(trace1, trace2):\n",
    "  return distance_faster(trace1, trace2, sync_move_levenshtein)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Prepare Sepsis event log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"training_set_sepsis.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"training_set_sepsis.csv\",\n",
    "                   dtype = {'pL:low' : np.float64,\n",
    "                                'pL:high' : np.float64,\n",
    "                                'pW:low' : np.float64,\n",
    "                                'pW:high' : np.float64,\n",
    "                                'sM:low' : np.float64,\n",
    "                                'sM:high' : np.float64})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = data[['Case ID', 'Activity', \n",
    "                 'pL:low', 'pL:high', 'pW:low', 'pW:high',\n",
    "                 'sM:low', 'sM:high']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test1 = pd.read_csv(\"test_set_sepsis.csv\",\n",
    "                       dtype = {'pL:low' : np.float64,\n",
    "                                'pL:high' : np.float64,\n",
    "                                'pW:low' : np.float64,\n",
    "                                'pW:high' : np.float64,\n",
    "                                'sM:low' : np.float64,\n",
    "                                'sM:high' : np.float64})\n",
    "df_test2 = pd.read_csv(\"test_set_result_sepsis.csv\", \n",
    "                       dtype = {'pL:low' : np.float64,\n",
    "                                'pL:high' : np.float64,\n",
    "                                'pW:low' : np.float64,\n",
    "                                'pW:high' : np.float64,\n",
    "                                'sM:low' : np.float64,\n",
    "                                'sM:high' : np.float64})\n",
    "\n",
    "df_test1 = df_test1[['Case ID', 'Activity', \n",
    "                 'pL:low', 'pL:high', 'pW:low', 'pW:high',\n",
    "                 'sM:low', 'sM:high']]\n",
    "\n",
    "df_test2 = df_test2[['Case ID', 'Activity', \n",
    "                 'pL:low', 'pL:high', 'pW:low', 'pW:high',\n",
    "                 'sM:low', 'sM:high']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = lambda x: [{\"label\": y['Activity'], \n",
    "                \"data\": {\"pL:low\": y['pL:low'] , \"pL:high\": y['pL:high'],\n",
    "                         \"pW:low\": y['pW:low'] , \"pW:high\": y['pW:high'],\n",
    "                         \"sM:low\": y['sM:low'] , \"sM:high\": y['sM:high'],\n",
    "                         }  } for index, y in x.iterrows()]\n",
    "\n",
    "g = lambda x: [{\"label\": y['Activity'], \n",
    "                \"data\": {\"pL\": y['pL:low'] , \n",
    "                         \"pW\": y['pW:low'] , \n",
    "                         \"sM\": y['sM:low']  }  } for index, y in x.iterrows()]\n",
    "\n",
    "\n",
    "trace_train = df_train.groupby('Case ID')[['Activity', 'pL:low', 'pL:high', 'pW:low', 'pW:high',\n",
    "                 'sM:low', 'sM:high']].apply(f).reset_index()\n",
    "\n",
    "trace_test1 = df_test1.groupby('Case ID')[['Activity', 'pL:low', 'pL:high', 'pW:low', 'pW:high',\n",
    "                 'sM:low', 'sM:high']].apply(g).reset_index()\n",
    "\n",
    "trace_test2 = df_test2.groupby('Case ID')[['Activity', 'pL:low', 'pL:high', 'pW:low', 'pW:high',\n",
    "                 'sM:low', 'sM:high']].apply(f).reset_index()\n",
    "\n",
    "trace_train.index = trace_train['Case ID']\n",
    "trace_train = trace_train.drop('Case ID', axis=1)\n",
    "\n",
    "trace_test1.index = trace_test1['Case ID']\n",
    "trace_test1 = trace_test1.drop('Case ID', axis=1)\n",
    "\n",
    "trace_test2.index = trace_test2['Case ID']\n",
    "trace_test2 = trace_test2.drop('Case ID', axis=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Save the ground truth of original traces (Sepsis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = list()\n",
    "for row1 in range(len(trace_test2)):\n",
    "    predict = list()\n",
    "    for row2 in range(len(trace_train)):\n",
    "        if str(trace_test2[0][row1]) == str(trace_train[0][row2]):\n",
    "            predict.append(trace_train.index[row2])\n",
    "    \n",
    "    label.append(predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"label_sepsis\", \"wb\") as fp:   #Pickling\n",
    "    pickle.dump(label, fp)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Generate Encoded matrix (Sepsis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "acts = df_train.Activity.unique().tolist()\n",
    "attrs = ['pL', 'pW', 'sM']\n",
    "attrs_expand = [x + \":\" + y for x in acts for y in attrs]\n",
    "\n",
    "pd.options.display.float_format = '{:.0f}'.format\n",
    "for attr in attrs_expand:\n",
    "    df_train[attr] = 0\n",
    "    for row in range(len(df_train)):\n",
    "        if df_train['Activity'][row] in attr:\n",
    "            df_train[attr][row] = str([format(df_train[str.split(attr, ':')[1]+':low'][row], '.1f'), format(df_train[str.split(attr, ':')[1]+':high'][row], '.1f')])\n",
    "        else:\n",
    "            df_train[attr][row] = str([str(np.nan), str(np.nan)])\n",
    "            \n",
    "            \n",
    "pd.options.display.float_format = '{:.0f}'.format\n",
    "for attr in attrs_expand:\n",
    "    df_test1[attr] = 0\n",
    "    for row in range(len(df_test1)):\n",
    "        if df_test1['Activity'][row] in attr:\n",
    "            df_test1[attr][row] = str([format(df_test1[str.split(attr, ':')[1]+':low'][row], '.1f'), format(df_test1[str.split(attr, ':')[1]+':high'][row], '.1f')])\n",
    "        else:\n",
    "            df_test1[attr][row] = str([str(np.nan), str(np.nan)]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_train_transformed = pd.get_dummies(df_train[ ['Case ID', 'Activity'] + attrs_expand], columns=attrs_expand)\n",
    "dt_test_transformed = pd.get_dummies(df_test1[ ['Case ID', 'Activity'] + attrs_expand], columns=attrs_expand)\n",
    "\n",
    "import ast\n",
    "cols = dt_train_transformed.columns[2:].tolist()\n",
    "\n",
    "for row in range(len(dt_train_transformed)):\n",
    "    for attr in attrs_expand:\n",
    "        x = ast.literal_eval(df_train[attr][row])\n",
    "        x_low = float(x[0])\n",
    "        x_high = float(x[1])\n",
    "        \n",
    "        cols_x = [s for s in cols if attr in s]\n",
    "        for tcol in cols_x:\n",
    "            y = ast.literal_eval(str.split(tcol,'_')[1])\n",
    "            y_low = float(y[0])\n",
    "            y_high = float(y[1])\n",
    "            if x_low >= y_low and x_high <= y_high:\n",
    "                dt_train_transformed[tcol][row] = 1\n",
    "                \n",
    "dt_test1_transformed = pd.DataFrame(0, index=np.arange(len(df_test1)) , columns= cols)\n",
    "dt_test1_transformed.head()\n",
    "\n",
    "for row in range(len(df_test1)):\n",
    "    for attr in attrs_expand:\n",
    "        x = ast.literal_eval(df_test1[attr][row])\n",
    "        x_low = float(x[0])\n",
    "        x_high = float(x[1])\n",
    "        \n",
    "        cols_x = [s for s in cols if attr in s]\n",
    "        for tcol in cols_x:\n",
    "            y = ast.literal_eval(str.split(tcol,'_')[1])\n",
    "            y_low = float(y[0])\n",
    "            y_high = float(y[1])\n",
    "            if x_low >= y_low and x_high <= y_high:\n",
    "                dt_test1_transformed[tcol][row] = 1\n",
    "                \n",
    "dt_test1_transformed = pd.concat([df_test1[['Case ID', 'Activity']], dt_test1_transformed], axis=1)\n",
    "dt_test1_transformed['Case ID'] = ['test_' + i for i in dt_test1_transformed['Case ID']]\n",
    "\n",
    "df = pd.concat([dt_train_transformed, dt_test1_transformed]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers.LastStateTransformer import LastStateTransformer\n",
    "from transformers.AggregateTransformer import AggregateTransformer\n",
    "from transformers.IndexBasedTransformer import IndexBasedTransformer\n",
    "from transformers.AggregateNgramTransformer20 import AggregateNgramTransformer\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "dir_home = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "m=1\n",
    "\n",
    "pipe = Pipeline(steps=[\n",
    "        (\"AggregateTransformer\", AggregateTransformer(case_id_col = 'Case ID',\n",
    "                        cat_cols = ['Activity'], \n",
    "                        num_cols = cols))\n",
    "        ])\n",
    "encoded_df = pipe.fit_transform(df)\n",
    "encoded_df.to_csv(dir_home+\"/data_trans/sepsis8_aggregate_\" + str(m) + \".csv\", index= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline(steps=[\n",
    "        (\"AggregateTransformer\", AggregateTransformer(case_id_col = 'Case ID',\n",
    "                        cat_cols = ['Activity'] , \n",
    "                        num_cols = cols,\n",
    "                        boolean= True))\n",
    "        ])\n",
    "encoded_df = pipe.fit_transform(df)\n",
    "encoded_df.to_csv(dir_home+\"/data_trans/sepsis8_bool_\" + str(m) + \".csv\", index= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline(steps=[\n",
    "        (\"IndexBasedTransformer\", IndexBasedTransformer(case_id_col = 'Case ID',\n",
    "                        cat_cols = ['Activity'] , \n",
    "                        num_cols = cols))\n",
    "        ])\n",
    "encoded_df = pipe.fit_transform(df)\n",
    "encoded_df.to_csv(dir_home+\"/data_trans/sepsis8_index_\" + str(m) + \".csv\", index= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline(steps=[\n",
    "        (\"AggregateNgramTransformer\", AggregateNgramTransformer(case_id_col = 'Case ID',\n",
    "                        act_col = 'Activity', n=2 , v= 0.7,\n",
    "                        cat_cols = ['A1_Diagnose'],\n",
    "                        num_cols = ['A2_CRP']))\n",
    "        ])\n",
    "encoded_df = pipe.fit_transform(df)\n",
    "\n",
    "encoded_df.to_csv(dir_home+\"/data_trans/sepsis8_aggngram2_\" + str(m) + \".csv\", index= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline(steps=[\n",
    "        (\"LastStateTransformer\", LastStateTransformer(case_id_col = 'Case ID',\n",
    "                        cat_cols = ['Activity'] , \n",
    "                        num_cols = cols))\n",
    "        ])\n",
    "encoded_df = pipe.fit_transform(df)\n",
    "encoded_df.to_csv(dir_home+\"/data_trans/sepsis8_laststate_\" + str(m) + \".csv\", index= True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "================================================================================"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Prepare Road Fines event log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"training_set_roadfines.csv\",\n",
    "                   dtype = {'amount:low' : np.float64,\n",
    "                                'amount:high' : np.float64,\n",
    "                                'dismissal:low' : np.float64,\n",
    "                                'dismissal:high' : np.float64,\n",
    "                                'points:low' : np.float64,\n",
    "                                'points:high' : np.float64,\n",
    "                                'paymentAmount:low' : np.float64,\n",
    "                                'paymentAmount:high' : np.float64,\n",
    "                                'expense:low' : np.float64,\n",
    "                                'expense:high' : np.float64})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = data[['Case ID', 'Activity', \n",
    "                 'amount:low', 'amount:high', 'dismissal:low', 'dismissal:high',\n",
    "                 'points:low', 'points:high', 'paymentAmount:low', \n",
    "                 'paymentAmount:high', 'expense:low', 'expense:high']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Case ID</th>\n",
       "      <th>Activity</th>\n",
       "      <th>Variant</th>\n",
       "      <th>Variant index</th>\n",
       "      <th>amount:low</th>\n",
       "      <th>amount:high</th>\n",
       "      <th>dismissal:low</th>\n",
       "      <th>dismissal:high</th>\n",
       "      <th>points:low</th>\n",
       "      <th>points:high</th>\n",
       "      <th>paymentAmount:low</th>\n",
       "      <th>paymentAmount:high</th>\n",
       "      <th>expense:low</th>\n",
       "      <th>expense:high</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>case 0</td>\n",
       "      <td>Create Fine</td>\n",
       "      <td>Variant 42</td>\n",
       "      <td>42</td>\n",
       "      <td>-9.223372e+18</td>\n",
       "      <td>9.223372e+18</td>\n",
       "      <td>-9.223372e+18</td>\n",
       "      <td>9.223372e+18</td>\n",
       "      <td>-9.223372e+18</td>\n",
       "      <td>9.223372e+18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>case 1</td>\n",
       "      <td>Create Fine</td>\n",
       "      <td>Variant 42</td>\n",
       "      <td>42</td>\n",
       "      <td>-9.223372e+18</td>\n",
       "      <td>9.223372e+18</td>\n",
       "      <td>-9.223372e+18</td>\n",
       "      <td>9.223372e+18</td>\n",
       "      <td>-9.223372e+18</td>\n",
       "      <td>9.223372e+18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>case 2</td>\n",
       "      <td>Create Fine</td>\n",
       "      <td>Variant 60</td>\n",
       "      <td>60</td>\n",
       "      <td>3.800000e+01</td>\n",
       "      <td>4.100000e+01</td>\n",
       "      <td>-9.223372e+18</td>\n",
       "      <td>9.223372e+18</td>\n",
       "      <td>-9.223372e+18</td>\n",
       "      <td>9.223372e+18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>case 2</td>\n",
       "      <td>Payment</td>\n",
       "      <td>Variant 60</td>\n",
       "      <td>60</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-9.223372e+18</td>\n",
       "      <td>9.223372e+18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>case 3</td>\n",
       "      <td>Create Fine</td>\n",
       "      <td>Variant 42</td>\n",
       "      <td>42</td>\n",
       "      <td>-9.223372e+18</td>\n",
       "      <td>9.223372e+18</td>\n",
       "      <td>-9.223372e+18</td>\n",
       "      <td>9.223372e+18</td>\n",
       "      <td>-9.223372e+18</td>\n",
       "      <td>9.223372e+18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Case ID     Activity     Variant  Variant index    amount:low   amount:high  \\\n",
       "0  case 0  Create Fine  Variant 42             42 -9.223372e+18  9.223372e+18   \n",
       "1  case 1  Create Fine  Variant 42             42 -9.223372e+18  9.223372e+18   \n",
       "2  case 2  Create Fine  Variant 60             60  3.800000e+01  4.100000e+01   \n",
       "3  case 2      Payment  Variant 60             60           NaN           NaN   \n",
       "4  case 3  Create Fine  Variant 42             42 -9.223372e+18  9.223372e+18   \n",
       "\n",
       "   dismissal:low  dismissal:high    points:low   points:high  \\\n",
       "0  -9.223372e+18    9.223372e+18 -9.223372e+18  9.223372e+18   \n",
       "1  -9.223372e+18    9.223372e+18 -9.223372e+18  9.223372e+18   \n",
       "2  -9.223372e+18    9.223372e+18 -9.223372e+18  9.223372e+18   \n",
       "3            NaN             NaN           NaN           NaN   \n",
       "4  -9.223372e+18    9.223372e+18 -9.223372e+18  9.223372e+18   \n",
       "\n",
       "   paymentAmount:low  paymentAmount:high  expense:low  expense:high  \n",
       "0                NaN                 NaN          NaN           NaN  \n",
       "1                NaN                 NaN          NaN           NaN  \n",
       "2                NaN                 NaN          NaN           NaN  \n",
       "3      -9.223372e+18        9.223372e+18          NaN           NaN  \n",
       "4                NaN                 NaN          NaN           NaN  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test1 = pd.read_csv(\"test_set_roadfines.csv\",\n",
    "                       dtype = {'amount:low' : np.float64,\n",
    "                                'amount:high' : np.float64,\n",
    "                                'dismissal:low' : np.float64,\n",
    "                                'dismissal:high' : np.float64,\n",
    "                                'points:low' : np.float64,\n",
    "                                'points:high' : np.float64,\n",
    "                                'paymentAmount:low' : np.float64,\n",
    "                                'paymentAmount:high' : np.float64,\n",
    "                                'expense:low' : np.float64,\n",
    "                                'expense:high' : np.float64})\n",
    "df_test2 = pd.read_csv(\"test_set_result_roadfines.csv\", \n",
    "                       dtype = {'amount:low' : np.float64,\n",
    "                                'amount:high' : np.float64,\n",
    "                                'dismissal:low' : np.float64,\n",
    "                                'dismissal:high' : np.float64,\n",
    "                                'points:low' : np.float64,\n",
    "                                'points:high' : np.float64,\n",
    "                                'paymentAmount:low' : np.float64,\n",
    "                                'paymentAmount:high' : np.float64,\n",
    "                                'expense:low' : np.float64,\n",
    "                                'expense:high' : np.float64})\n",
    "df_test2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Case ID</th>\n",
       "      <th>Activity</th>\n",
       "      <th>amount:low</th>\n",
       "      <th>amount:high</th>\n",
       "      <th>dismissal:low</th>\n",
       "      <th>dismissal:high</th>\n",
       "      <th>points:low</th>\n",
       "      <th>points:high</th>\n",
       "      <th>paymentAmount:low</th>\n",
       "      <th>paymentAmount:high</th>\n",
       "      <th>expense:low</th>\n",
       "      <th>expense:high</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>case 0</td>\n",
       "      <td>Create Fine</td>\n",
       "      <td>-9.223372e+18</td>\n",
       "      <td>9.223372e+18</td>\n",
       "      <td>-9.223372e+18</td>\n",
       "      <td>9.223372e+18</td>\n",
       "      <td>-9.223372e+18</td>\n",
       "      <td>9.223372e+18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>case 1</td>\n",
       "      <td>Create Fine</td>\n",
       "      <td>-9.223372e+18</td>\n",
       "      <td>9.223372e+18</td>\n",
       "      <td>-9.223372e+18</td>\n",
       "      <td>9.223372e+18</td>\n",
       "      <td>-9.223372e+18</td>\n",
       "      <td>9.223372e+18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>case 2</td>\n",
       "      <td>Create Fine</td>\n",
       "      <td>3.800000e+01</td>\n",
       "      <td>4.100000e+01</td>\n",
       "      <td>-9.223372e+18</td>\n",
       "      <td>9.223372e+18</td>\n",
       "      <td>-9.223372e+18</td>\n",
       "      <td>9.223372e+18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>case 2</td>\n",
       "      <td>Payment</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-9.223372e+18</td>\n",
       "      <td>9.223372e+18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>case 3</td>\n",
       "      <td>Create Fine</td>\n",
       "      <td>-9.223372e+18</td>\n",
       "      <td>9.223372e+18</td>\n",
       "      <td>-9.223372e+18</td>\n",
       "      <td>9.223372e+18</td>\n",
       "      <td>-9.223372e+18</td>\n",
       "      <td>9.223372e+18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Case ID     Activity    amount:low   amount:high  dismissal:low  \\\n",
       "0  case 0  Create Fine -9.223372e+18  9.223372e+18  -9.223372e+18   \n",
       "1  case 1  Create Fine -9.223372e+18  9.223372e+18  -9.223372e+18   \n",
       "2  case 2  Create Fine  3.800000e+01  4.100000e+01  -9.223372e+18   \n",
       "3  case 2      Payment           NaN           NaN            NaN   \n",
       "4  case 3  Create Fine -9.223372e+18  9.223372e+18  -9.223372e+18   \n",
       "\n",
       "   dismissal:high    points:low   points:high  paymentAmount:low  \\\n",
       "0    9.223372e+18 -9.223372e+18  9.223372e+18                NaN   \n",
       "1    9.223372e+18 -9.223372e+18  9.223372e+18                NaN   \n",
       "2    9.223372e+18 -9.223372e+18  9.223372e+18                NaN   \n",
       "3             NaN           NaN           NaN      -9.223372e+18   \n",
       "4    9.223372e+18 -9.223372e+18  9.223372e+18                NaN   \n",
       "\n",
       "   paymentAmount:high  expense:low  expense:high  \n",
       "0                 NaN          NaN           NaN  \n",
       "1                 NaN          NaN           NaN  \n",
       "2                 NaN          NaN           NaN  \n",
       "3        9.223372e+18          NaN           NaN  \n",
       "4                 NaN          NaN           NaN  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test1 = df_test1[['Case ID', 'Activity', \n",
    "                 'amount:low', 'amount:high', 'dismissal:low', 'dismissal:high',\n",
    "                 'points:low', 'points:high', 'paymentAmount:low', \n",
    "                 'paymentAmount:high', 'expense:low', 'expense:high']]\n",
    "\n",
    "df_test2 = df_test2[['Case ID', 'Activity', \n",
    "                 'amount:low', 'amount:high', 'dismissal:low', 'dismissal:high',\n",
    "                 'points:low', 'points:high', 'paymentAmount:low', \n",
    "                 'paymentAmount:high', 'expense:low', 'expense:high']]\n",
    "df_test2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = lambda x: [{\"label\": y['Activity'], \n",
    "                \"data\": {\"amount:low\": y['amount:low'] , \"amount:high\": y['amount:high'],\n",
    "                         \"dismissal:low\": y['dismissal:low'] , \"dismissal:high\": y['dismissal:high'],\n",
    "                         \"points:low\": y['points:low'] , \"points:high\": y['points:high'],\n",
    "                         \"paymentAmount:low\": y['paymentAmount:low'] , \"paymentAmount:high\": y['paymentAmount:high'],\n",
    "                         \"expense:low\": y['expense:low'] , \"expense:high\": y['expense:high']}  } for index, y in x.iterrows()]\n",
    "\n",
    "g = lambda x: [{\"label\": y['Activity'], \n",
    "                \"data\": {\"amount\": y['amount:low'] , \n",
    "                         \"dismissal\": y['dismissal:low'] , \n",
    "                         \"points\": y['points:low'] , \n",
    "                         \"paymentAmount\": y['paymentAmount:low'] , \n",
    "                         \"expense\": y['expense:low'] }  } for index, y in x.iterrows()]\n",
    "\n",
    "\n",
    "trace_train = df_train.groupby('Case ID')[['Activity', 'amount:low', 'amount:high', 'dismissal:low', 'dismissal:high',\n",
    "                 'points:low', 'points:high', 'paymentAmount:low', \n",
    "                 'paymentAmount:high', 'expense:low', 'expense:high']].apply(f).reset_index()\n",
    "\n",
    "trace_test1 = df_test1.groupby('Case ID')[['Activity', 'amount:low', 'amount:high', 'dismissal:low', 'dismissal:high',\n",
    "                 'points:low', 'points:high', 'paymentAmount:low', \n",
    "                 'paymentAmount:high', 'expense:low', 'expense:high']].apply(g).reset_index()\n",
    "\n",
    "trace_test2 = df_test2.groupby('Case ID')[['Activity', 'amount:low', 'amount:high', 'dismissal:low', 'dismissal:high',\n",
    "                 'points:low', 'points:high', 'paymentAmount:low', \n",
    "                 'paymentAmount:high', 'expense:low', 'expense:high']].apply(f).reset_index()\n",
    "\n",
    "trace_train.index = trace_train['Case ID']\n",
    "trace_train = trace_train.drop('Case ID', axis=1)\n",
    "\n",
    "trace_test1.index = trace_test1['Case ID']\n",
    "trace_test1 = trace_test1.drop('Case ID', axis=1)\n",
    "\n",
    "trace_test2.index = trace_test2['Case ID']\n",
    "trace_test2 = trace_test2.drop('Case ID', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For statistics\n",
    "\n",
    "attrs = ['amount', 'dismissal', 'points', 'paymentAmount', 'expense']\n",
    "df_train2 = df_train.copy()\n",
    "for attr in attrs:\n",
    "    df_train2[attr] = 0\n",
    "    for row in range(len(df_train2)):\n",
    "        df_train2[attr][row] = str([str(df_train2[attr+':low'][row]), str(df_train2[attr+':high'][row])]) \n",
    "       \n",
    "        \n",
    "df_train2 = df_train2.drop(columns = ['amount:low', 'amount:high', 'dismissal:low', 'dismissal:high',\n",
    "                 'points:low', 'points:high', 'paymentAmount:low', \n",
    "                 'paymentAmount:high', 'expense:low', 'expense:high'], \n",
    "                  axis =1).reset_index(drop=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Save the ground truth of original traces (Road Fines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = list()\n",
    "for row1 in range(len(trace_test2)):\n",
    "    predict = list()\n",
    "    for row2 in range(len(trace_train)):\n",
    "        if str(trace_test2[0][row1]) == str(trace_train[0][row2]):\n",
    "            predict.append(trace_train.index[row2])\n",
    "    \n",
    "    label.append(predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(\"label_road\", \"wb\") as fp:   #Pickling\n",
    "    pickle.dump(label, fp)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Generate Encoded matrix (Road Fines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "acts = df_train.Activity.unique().tolist()\n",
    "attrs = ['amount', 'dismissal', 'points', 'paymentAmount', 'expense']\n",
    "attrs_expand = [x + \":\" + y for x in acts for y in attrs]\n",
    "\n",
    "pd.options.display.float_format = '{:.0f}'.format\n",
    "for attr in attrs_expand:\n",
    "    df_train[attr] = 0\n",
    "    for row in range(len(df_train)):\n",
    "        if df_train['Activity'][row] in attr:\n",
    "            df_train[attr][row] = str([format(df_train[str.split(attr, ':')[1]+':low'][row], '.1f'), format(df_train[str.split(attr, ':')[1]+':high'][row], '.1f')])\n",
    "        else:\n",
    "            df_train[attr][row] = str([str(np.nan), str(np.nan)])\n",
    "            \n",
    "            \n",
    "pd.options.display.float_format = '{:.0f}'.format\n",
    "for attr in attrs_expand:\n",
    "    df_test1[attr] = 0\n",
    "    for row in range(len(df_test1)):\n",
    "        if df_test1['Activity'][row] in attr:\n",
    "            df_test1[attr][row] = str([format(df_test1[str.split(attr, ':')[1]+':low'][row], '.1f'), format(df_test1[str.split(attr, ':')[1]+':high'][row], '.1f')])\n",
    "        else:\n",
    "            df_test1[attr][row] = str([str(np.nan), str(np.nan)]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_train_transformed = pd.get_dummies(df_train[ ['Case ID', 'Activity'] + attrs_expand], columns=attrs_expand)\n",
    "dt_test_transformed = pd.get_dummies(df_test1[ ['Case ID', 'Activity'] + attrs_expand], columns=attrs_expand)\n",
    "\n",
    "import ast\n",
    "cols = dt_train_transformed.columns[2:].tolist()\n",
    "\n",
    "for row in range(len(dt_train_transformed)):\n",
    "    for attr in attrs_expand:\n",
    "        x = ast.literal_eval(df_train[attr][row])\n",
    "        x_low = float(x[0])\n",
    "        x_high = float(x[1])\n",
    "        \n",
    "        cols_x = [s for s in cols if attr in s]\n",
    "        for tcol in cols_x:\n",
    "            y = ast.literal_eval(str.split(tcol,'_')[1])\n",
    "            y_low = float(y[0])\n",
    "            y_high = float(y[1])\n",
    "            if x_low >= y_low and x_high <= y_high:\n",
    "                dt_train_transformed[tcol][row] = 1\n",
    "                \n",
    "dt_test1_transformed = pd.DataFrame(0, index=np.arange(len(df_test1)) , columns= cols)\n",
    "dt_test1_transformed.head()\n",
    "\n",
    "for row in range(len(df_test1)):\n",
    "    for attr in attrs_expand:\n",
    "        x = ast.literal_eval(df_test1[attr][row])\n",
    "        x_low = float(x[0])\n",
    "        x_high = float(x[1])\n",
    "        \n",
    "        cols_x = [s for s in cols if attr in s]\n",
    "        for tcol in cols_x:\n",
    "            y = ast.literal_eval(str.split(tcol,'_')[1])\n",
    "            y_low = float(y[0])\n",
    "            y_high = float(y[1])\n",
    "            if x_low >= y_low and x_high <= y_high:\n",
    "                dt_test1_transformed[tcol][row] = 1\n",
    "                \n",
    "dt_test1_transformed = pd.concat([df_test1[['Case ID', 'Activity']], dt_test1_transformed], axis=1)\n",
    "dt_test1_transformed['Case ID'] = ['test_' + i for i in dt_test1_transformed['Case ID']]\n",
    "\n",
    "df = pd.concat([dt_train_transformed, dt_test1_transformed]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers.LastStateTransformer import LastStateTransformer\n",
    "from transformers.AggregateTransformer import AggregateTransformer\n",
    "from transformers.IndexBasedTransformer import IndexBasedTransformer\n",
    "from transformers.AggregateNgramTransformer20 import AggregateNgramTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "dir_home = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "m=1\n",
    "\n",
    "pipe = Pipeline(steps=[\n",
    "        (\"AggregateTransformer\", AggregateTransformer(case_id_col = 'Case ID',\n",
    "                        cat_cols = ['Activity']+ cols, \n",
    "                        num_cols = []))\n",
    "        ])\n",
    "encoded_df = pipe.fit_transform(df)\n",
    "encoded_df.to_csv(dir_home+\"/data_trans/road_aggregate_\" + str(m) + \".csv\", index= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline(steps=[\n",
    "        (\"AggregateTransformer\", AggregateTransformer(case_id_col = 'Case ID',\n",
    "                        cat_cols = ['Activity'] +cols, \n",
    "                        num_cols = [],\n",
    "                        boolean= True))\n",
    "        ])\n",
    "encoded_df = pipe.fit_transform(df)\n",
    "encoded_df.to_csv(dir_home+\"/data_trans/road_bool_\" + str(m) + \".csv\", index= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline(steps=[\n",
    "        (\"IndexBasedTransformer\", IndexBasedTransformer(case_id_col = 'Case ID',\n",
    "                        cat_cols = ['Activity']+cols , \n",
    "                        num_cols = []))\n",
    "        ])\n",
    "encoded_df = pipe.fit_transform(df)\n",
    "encoded_df.to_csv(dir_home+\"/data_trans/road_index_\" + str(m) + \".csv\", index= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline(steps=[\n",
    "        (\"AggregateNgramTransformer\", AggregateNgramTransformer(case_id_col = 'Case ID',\n",
    "                        act_col = 'Activity', n=2 , v= 0.7,\n",
    "                        cat_cols = cols,\n",
    "                        num_cols = []))\n",
    "        ])\n",
    "encoded_df = pipe.fit_transform(df)\n",
    "encoded_df.to_csv(dir_home+\"/data_trans/road_aggngram2_\" + str(m) + \".csv\", index= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline(steps=[\n",
    "        (\"LastStateTransformer\", LastStateTransformer(case_id_col = 'Case ID',\n",
    "                        cat_cols = ['Activity'] + cols , \n",
    "                        num_cols = []))\n",
    "        ])\n",
    "encoded_df = pipe.fit_transform(df)\n",
    "encoded_df.to_csv(dir_home+\"/data_trans/road_laststate_\" + str(m) + \".csv\", index= True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "================================================================"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9b13726099ff4a9270d97cd5a303046c40236cea9d4b3d3acf7f22861afad882"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
